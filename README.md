# Case TÃ©cnico Data Architect - iFood

## ğŸ“‹ Sobre o Projeto

Este projeto implementa uma soluÃ§Ã£o completa de ingestÃ£o, processamento e anÃ¡lise de dados de corridas de tÃ¡xi de Nova York (NYC TLC Trip Record Data) utilizando uma arquitetura de Data Lake em camadas.

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

A soluÃ§Ã£o foi construÃ­da seguindo o padrÃ£o de arquitetura medalhÃ£o com uma Landing Zone:

### 1. **Landing Layer**
- **LocalizaÃ§Ã£o**: `s3://datalake-ifood/landing_layer/yellow/`
- **Formato**: Parquet (arquivos originais)
- **PropÃ³sito**: Armazenamento dos dados brutos sem transformaÃ§Ã£o
- **Processo**: Script `extract_to_landing.py`

### 2. **Raw Layer** (Bronze)
- **LocalizaÃ§Ã£o**: `s3://datalake-ifood/raw_layer/tb_taxi_data_api/`
- **Formato**: Delta Lake
- **PropÃ³sito**: Dados estruturados com validaÃ§Ãµes e padronizaÃ§Ãµes
- **Processo**: Script `landing_to_raw.py`
- **CaracterÃ­sticas**:
  - Schema enforcement
  - ValidaÃ§Ã£o de tipos de dados
  - Tratamento de colunas faltantes
  - Particionamento por `date_reference` e `VendorID`

### 3. **Trusted Layer** (Silver)
- **LocalizaÃ§Ã£o**: `s3://datalake-ifood/trusted_layer/tb_taxi_data_for_analysis/`
- **Formato**: Delta Lake
- **PropÃ³sito**: Dados otimizados para consumo e anÃ¡lise
- **Processo**: Script `raw_to_trusted.sql`
- **CaracterÃ­sticas**:
  - Apenas colunas necessÃ¡rias para anÃ¡lise
  - Dados deduplicated
  - Otimizado para queries analÃ­ticas

## Databricks Catalog + AWS S3
- **Bucket**: `s3://datalake-ifood`
- **CatÃ¡logo**: `ifood_catalog`

## Desenho da arquitetura


                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚  â˜ï¸  AWS S3: datalake-ifood     â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                            â”‚                            â”‚
                    â–¼                            â–¼                            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ğŸ“¦ Landing Layer      â”‚   â”‚ ğŸ“Š Raw Layer         â”‚    â”‚ ğŸ¯ Trusted Layer     â”‚
        â”‚ landing_layer/yellow/ â”‚   â”‚ raw_layer/            â”‚   â”‚ trusted_layer/        â”‚
        â”‚ (Parquet files)       â”‚   â”‚ (Delta tables)        â”‚   â”‚ (Delta tables)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                            â–²                            â–²
                    â”‚ write                      â”‚ write                      â”‚ write
                    â”‚                            â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚                            â”‚
    â”‚ ğŸ“¥ TASK 1                â”‚                 â”‚                            â”‚
    â”‚ extract_to_landing.py    â”‚                 â”‚                            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚                            â”‚
    â”‚ â€¢ Download NYC TLC data  â”‚                 â”‚                            â”‚
    â”‚ â€¢ Upload to S3 Landing   â”‚                 â”‚                            â”‚
    â”‚ â€¢ Check duplicates       â”‚                 â”‚                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚                            â”‚
                 â”‚ depends_on                    â”‚                            â”‚
                 â”‚                               â”‚                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚                            â”‚
    â”‚ ğŸ”„ TASK 2                â”‚                 â”‚                            â”‚
    â”‚ landing_to_raw.py        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ read from Landing                            â”‚
    â”‚ â€¢ Read Parquet files     â”‚ write to Raw                                 â”‚
    â”‚ â€¢ Validate schema        â”‚                                              â”‚
    â”‚ â€¢ Apply transformations  â”‚                                              â”‚
    â”‚ â€¢ Write Delta to Raw     â”‚                                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
                 â”‚ depends_on                                                 â”‚
                 â”‚                                                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â” â”‚
    â”‚ âœ¨ TASK 3: raw_to_trusted.sql                                        â”‚  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
    â”‚                                                                       â”‚ â”‚
    â”‚  STEP 1: CREATE TEMPORARY TABLE                                       â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
    â”‚  â”‚ ğŸ“ tmp_tb_taxi_data_for_analysis                                â”‚  â”‚ â”‚
    â”‚  â”‚ Location: s3://datalake-ifood/trusted_layer/tmp/                â”‚  â”‚ â”‚
    â”‚  â”‚                                                                 â”‚  â”‚ â”‚
    â”‚  â”‚ â€¢ Read from Raw Layer                                           â”‚  â”‚ â”‚
    â”‚  â”‚ â€¢ Apply type conversions                                        â”‚  â”‚ â”‚
    â”‚  â”‚ â€¢ Create validation flags                                       â”‚  â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
    â”‚                                   â”‚                                   â”‚ â”‚
    â”‚                                   â”‚                                   â”‚ â”‚
    â”‚  STEP 2: DATA QUALITY VALIDATION                                      â”‚ â”‚
    â”‚                                   â”‚                                   â”‚ â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚
    â”‚              â”‚                    â”‚                    â”‚              â”‚ â”‚
    â”‚              â–¼                    â”‚                    â–¼              â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
    â”‚  â”‚ âœ… tem_erro = 0    â”‚           â”‚        â”‚ âŒ tem_erro = 1   â”‚     â”‚ â”‚
    â”‚  â”‚ (Valid Records)    â”‚           â”‚        â”‚ (Invalid Records)  â”‚    â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
    â”‚             â”‚                     â”‚                   â”‚              â”‚ â”‚
    â”‚             â”‚                     â”‚                   â”‚              â”‚ â”‚
    â”‚             â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ ğŸ“Š Quality Metrics     â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ â€¢ Total records        â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ â€¢ Error rate           â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ â€¢ Type validation      â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ â€¢ Business rules       â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚                        â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ ASSERT validations     â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â”‚ (threshold checks)     â”‚       â”‚              â”‚ â”‚
    â”‚             â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚              â”‚ â”‚
    â”‚             â”‚                     â”‚                   â”‚              â”‚ â”‚
    â”‚             â”‚                     â”‚ âœ… PASS           â”‚              â”‚ â”‚
    â”‚             â”‚                     â”‚                   â”‚              â”‚ â”‚
    â”‚  STEP 3:    â”‚                     â–¼                   â”‚  STEP 4:     â”‚ â”‚
    â”‚  INSERT     â”‚                                         â”‚  INSERT      â”‚ â”‚
    â”‚             â”‚                                         â”‚              â”‚ â”‚
    â”‚             â–¼                                         â–¼              â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
    â”‚  â”‚ ğŸ¯ tb_taxi_data_     â”‚              â”‚ ğŸš¨ tb_taxi_data_         â”‚ â”‚ â”‚
    â”‚  â”‚    for_analysis      â”‚              â”‚    quarentena            â”‚ â”‚ â”‚
    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â”‚
    â”‚  â”‚ â€¢ vendor_id          â”‚              â”‚ â€¢ All original fields    â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ tpep_pickup_*      â”‚              â”‚ â€¢ Validation flags       â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ tpep_dropoff_*     â”‚              â”‚ â€¢ motivos_erro           â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ passenger_count    â”‚              â”‚ â€¢ tipo_erro              â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ total_amount       â”‚              â”‚ â€¢ data_hora_quarentena   â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ trip_duration      â”‚              â”‚ â€¢ data_particao          â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ pickup_date        â”‚              â”‚                          â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ data_hora_carga    â”‚              â”‚ Categories:              â”‚ â”‚ â”‚
    â”‚  â”‚ â€¢ data_particao      â”‚              â”‚ â€¢ ERRO_TIPAGEM           â”‚ â”‚ â”‚
    â”‚  â”‚                      â”‚              â”‚ â€¢ ERRO_NULO              â”‚ â”‚ â”‚
    â”‚  â”‚ âœ… Analysis Ready    â”‚              â”‚ â€¢ ERRO_LOGICA_NEGOCIO    â”‚ â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â€¢ ERRO_VALIDACAO_RANGE   â”‚ â”‚ â”‚
    â”‚             â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
    â”‚             â”‚                                     â”‚                 â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                  â”‚                                     â”‚                   â”‚
                  â”‚ write to Trusted                    â”‚ write to Trusted  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
                                    â”‚                                       â”‚
                                    â–¼                                       â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ğŸ—„ï¸  UNITY CATALOG: ifood_catalog                               â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                                                  â”‚
        â”‚  ğŸ“‹ Schema: raw_layer                                            â”‚
        â”‚     â””â”€ Table: tb_taxi_data_api                                   â”‚
        â”‚        â”œâ”€ Location: s3://.../raw_layer/                          â”‚
        â”‚        â”œâ”€ Format: Delta                                          â”‚
        â”‚        â”œâ”€ Cluster by: date_reference, VendorID                   â”‚
        â”‚        â””â”€ Columns: 21 (all original fields)                      â”‚
        â”‚                                                                  â”‚
        â”‚  ğŸ“‹ Schema: trusted_layer                                        â”‚
        â”‚     â”œâ”€ Table: tmp_tb_taxi_data_for_analysis (TEMPORARY)          â”‚
        â”‚     â”‚  â”œâ”€ Location: s3://.../trusted_layer/tmp/                  â”‚
        â”‚     â”‚  â”œâ”€ Format: Delta                                          â”‚
        â”‚     â”‚  â””â”€ Contains: Raw data + validation flags                  â”‚
        â”‚     â”‚                                                            â”‚
        â”‚     â”œâ”€ Table: tb_taxi_data_for_analysis (FINAL)                  â”‚
        â”‚     â”‚  â”œâ”€ Location: s3://.../trusted_layer/                      â”‚
        â”‚     â”‚  â”œâ”€ Format: Delta                                          â”‚
        â”‚     â”‚  â”œâ”€ Cluster by: vendor_id                                  â”‚
        â”‚     â”‚  â””â”€ Columns: 5 core + metadata (valid records only)        â”‚
        â”‚     â”‚                                                            â”‚
        â”‚     â””â”€ Table: tb_taxi_data_quarentena (QUARANTINE)               â”‚
        â”‚        â”œâ”€ Location: s3://.../trusted_layer/quarentena/           â”‚
        â”‚        â”œâ”€ Format: Delta                                          â”‚
        â”‚        â”œâ”€ Partition by: data_particao_quarentena, tipo_erro      â”‚
        â”‚        â””â”€ Contains: Invalid records + error details              â”‚
        â”‚                                                                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚ query via SQL
                                    â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                             â”‚
                      â–¼                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ğŸ‘¥ Data Consumers       â”‚  â”‚  ğŸ”§ Data Quality Team        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ Analysts (SQL queries) â”‚  â”‚ â€¢ Monitor quarantine table   â”‚
        â”‚ â€¢ Data Scientists        â”‚  â”‚ â€¢ Analyze error patterns     â”‚
        â”‚ â€¢ Dashboards (BI tools)  â”‚  â”‚ â€¢ Fix data quality issues    â”‚
        â”‚ â€¢ ML Models              â”‚  â”‚ â€¢ Update validation rules    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                                  â”‚
                  â”‚                                  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Query only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        tb_taxi_data_for_analysis
                        (Clean, validated data)

ğŸ“… Schedule: Manual ou Cron

ğŸ–¥ï¸  Cluster: Serverless

â±ï¸  Total Duration: ~3 minutes (for 5 days)

## ğŸ› ï¸ Tecnologias Utilizadas

- **Apache Spark (PySpark)**: Processamento distribuÃ­do de dados
- **Delta Lake**: Formato de armazenamento ACID para Data Lakes
- **Databricks**: Plataforma de execuÃ§Ã£o e orquestraÃ§Ã£o
- **AWS S3**: Armazenamento de objetos
- **Unity Catalog**: GovernanÃ§a e metadados

## ğŸ“¦ Estrutura do RepositÃ³rio

```
ifood-case/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract_to_landing.py      # ExtraÃ§Ã£o de dados da API NYC TLC para Landing
â”‚   â”œâ”€â”€ landing_to_raw.py          # TransformaÃ§Ã£o Landing â†’ Raw com validaÃ§Ãµes
â”‚   â””â”€â”€ raw_to_trusted.sql         # TransformaÃ§Ã£o Raw â†’ Trusted (camada de consumo)
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ analise_dados.sql          # Queries analÃ­ticas solicitadas
â”œâ”€â”€ README.md                       # Este arquivo
â””â”€â”€ requirements.txt                # DependÃªncias Python
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

1. **Databricks Workspace** (Community Edition ou superior)
2. **AWS S3 Bucket** configurado
3. **Credenciais AWS** (Access Key ID e Secret Access Key)
4. **Unity Catalog** configurado no Databricks

### ConfiguraÃ§Ã£o Inicial

#### 1. Criar o CatÃ¡logo e Schemas

Execute o notebook `query_mapping_external_location.sql` para criar as estruturas necessÃ¡rias:

```sql
-- Criar schema para camada Raw
CREATE SCHEMA ifood_catalog.raw_layer
COMMENT 'Camada raw'
MANAGED LOCATION 's3://datalake-ifood/raw_layer/';

-- Criar schema para camada Trusted
CREATE SCHEMA ifood_catalog.trusted_layer
COMMENT 'Camada trusted'
MANAGED LOCATION 's3://datalake-ifood/trusted_layer/';
```

#### 2. Criar Job no Databricks

Crie um Databricks Job com as seguintes tasks encadeadas:

**Task 1: Extract to Landing**
```
Notebook: extract_to_landing.py
ParÃ¢metros:
  - aws_access_key_id: <sua_access_key>
  - aws_secret_access_key: <sua_secret_key>
  - datalake_path: s3://datalake-ifood/landing_layer
  - start_date: 2023-01
  - end_date: 2023-05
```

**Task 2: Landing to Raw** (depende de Task 1)
```
Notebook: landing_to_raw.py
ParÃ¢metros:
  - start_date: 2023-01
  - end_date: 2023-05
  - catalogo: ifood_catalog
  - schema: raw_layer
  - table: tb_taxi_data_api
```

**Task 3: Raw to Test to Trusted/Quarentena** (depende de Task 2)
```
Notebook: raw_to_trusted.sql
ParÃ¢metros:
  - catalogo: ifood_catalog
  - schema: trusted_layer
  - table: tb_taxi_data_for_analysis
```

### ExecuÃ§Ã£o Manual (Databricks Notebooks)

1. Importe os notebooks para o Databricks Workspace
2. Configure os widgets/parÃ¢metros conforme especificado acima
3. Execute na ordem: `extract_to_landing.py` â†’ `landing_to_raw.py` â†’ `raw_to_trusted.sql`

## ğŸ“Š AnÃ¡lises DisponÃ­veis

O arquivo `analysis/analise_dados.sql` contÃ©m as seguintes anÃ¡lises:

### 1. MÃ©dia de valor total por mÃªs
Calcula a mÃ©dia do `total_amount` recebido mensalmente considerando todos os tÃ¡xis yellow da frota.

### 2. MÃ©dia de passageiros por hora do dia em Maio/2023
Calcula a mÃ©dia de `passenger_count` para cada hora do dia no mÃªs de maio de 2023.

## ğŸ” DecisÃµes TÃ©cnicas

### Escolha do Delta Lake
- **ACID Transactions**: Garante consistÃªncia dos dados
- **Time Travel**: Permite auditoria e rollback
- **Schema Evolution**: Facilita adaptaÃ§Ã£o a mudanÃ§as no schema
- **OtimizaÃ§Ã£o de Performance**: Z-ordering e clustering

### ValidaÃ§Ãµes Implementadas

1. **ValidaÃ§Ã£o de Datas**: Formato YYYY-MM obrigatÃ³rio, datas futuras bloqueadas
2. **Schema Enforcement**: ValidaÃ§Ã£o rigorosa de tipos de dados
3. **Tratamento de Colunas**: 
   - Renomear colunas com case sensitivity incorreto
   - Criar colunas faltantes com valores NULL
4. **DeduplicaÃ§Ã£o**: RemoÃ§Ã£o de registros duplicados na camada Trusted
5. **IdempotÃªncia**: Processo DELETE antes de INSERT evita duplicaÃ§Ã£o

### Clustering Strategy

- **Raw Layer**: Clusterizado por `date_reference` e `VendorID` para otimizar queries filtradas por perÃ­odo e fornecedor
- **Trusted Layer**: Clusterizado por `vendor_id` para otimizar joins e agregaÃ§Ãµes

## ğŸ“ˆ Monitoramento e Logs

O projeto utiliza a biblioteca `loguru` para logging estruturado:

- âœ… **SUCCESS**: Dados persistidos com sucesso
- âš ï¸ **WARNING**: Arquivo jÃ¡ existe no bucket (evita duplicaÃ§Ã£o)
- âŒ **ERROR**: Falhas no processamento (com detalhamento do erro)
- â„¹ï¸ **INFO**: Eventos importantes do pipeline

## ğŸ”’ SeguranÃ§a

- Credenciais AWS passadas via widgets do Databricks (nunca hardcoded)
- Uso de IAM roles recomendado para ambientes produtivos
- Unity Catalog fornece governanÃ§a de acesso aos dados

## ğŸ“ DependÃªncias

```
loguru==0.7.2
boto3==1.34.0
python-dateutil==2.8.2
requests==2.31.0
pytz==2023.3
```

Instale com: `%pip install -r requirements.txt`

## ğŸ¯ Resultados Esperados

ApÃ³s execuÃ§Ã£o completa do pipeline:

1. **5 arquivos Parquet** na Landing Layer (Jan-Mai 2023)
2. **Tabela Delta `tb_taxi_data_api`** na Raw Layer com todas as colunas originais
3. **Tabela Delta `tb_taxi_data_for_analysis`** na Trusted Layer com apenas as 5 colunas necessÃ¡rias:
   - `vendor_id`
   - `tpep_pickup_datetime`
   - `tpep_dropoff_datetime`
   - `passenger_count`
   - `total_amount`

## ğŸ§ª Testes Implementados

### Testes de Schema
- VerificaÃ§Ã£o de colunas esperadas vs. colunas presentes
- ValidaÃ§Ã£o de tipos de dados
- Tratamento de colunas extras ou faltantes

### Testes de Dados
- DataFrame nÃ£o vazio apÃ³s transformaÃ§Ãµes
- Datas no formato correto
- Valores nulos controlados

## ğŸ› Troubleshooting

### Erro: "Colunas faltando"
- Verifique se o schema dos arquivos Parquet corresponde ao esperado
- Execute novamente a Task 2 com `treat_and_test` habilitado

### Erro: "Bucket nÃ£o encontrado"
- Verifique as credenciais AWS
- Confirme que o bucket existe e as permissÃµes estÃ£o corretas

### Erro: "Data jÃ¡ existe"
- Comportamento esperado (idempotÃªncia)
- O processo DELETE garante que dados antigos sejam removidos antes de inserir novos

## ğŸ‘¥ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como parte de um desafio tÃ©cnico para o iFood.